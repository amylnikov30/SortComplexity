{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import jpype\n",
    "import jpype.imports\n",
    "from jpype import startJVM, shutdownJVM, java, addClassPath, JClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement uniform testing (not exponential), think about using min, max, median, and mean when getting times for a particular array length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "startJVM(convertStrings=False, classpath=[\"../out/production/SortComplexity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37269\n"
     ]
    }
   ],
   "source": [
    "# java.lang.System.out.println(\"Hello world !\")\n",
    "try:\n",
    "    benchmark_class = JClass(\"stats.Benchmarks\")\n",
    "    print(benchmark_class.averageMergeSortTime(1000, 256))\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_file(filename, reset_text):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(reset_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exponential_sizes(start_size, base, x, n):\n",
    "    df = pd.DataFrame(columns=[\"size\", \"merge\", \"selection\"])\n",
    "    for i in range(x+1):\n",
    "        size = start_size + base**i\n",
    "        merge_time = benchmark_class.averageMergeSortTime(n, size)\n",
    "        selection_time = benchmark_class.averageSelectionSortTime(n, size)\n",
    "        \n",
    "        df.loc[len(df.index)] = [size, merge_time, selection_time]\n",
    "        \n",
    "    return df\n",
    "    \n",
    "    # os.system(f\"java -cp ../out/production/SortComplexity stats.Benchmarks {func} {n} {start_size + base ** i} ../analysis/{func}_times.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_crossover_point(base, x, n, start_size=0):\n",
    "    while True:\n",
    "        \n",
    "        times = run_exponential_sizes(start_size, base, x, n)\n",
    "        # initial_merge = pd.read_csv(\"merge_times.csv\")\n",
    "        \n",
    "        # run_exponential_sizes(start_size, base, x, n, \"selection\")\n",
    "        # initial_selec = pd.read_csv(\"selection_times.csv\")\n",
    "        \n",
    "        # reset_file(\"merge_times.csv\", \"size,time\\n\")\n",
    "        # reset_file(\"selection_times.csv\", \"size,time\\n\")\n",
    "\n",
    "        # times = initial_merge.merge(initial_selec, on=[\"size\"], suffixes=[\"_merge\", \"_selection\"])\n",
    "        # times.rename(columns={\"time_merge\": \"merge\", \"time_selection\": \"selection\"}, inplace=True)\n",
    "        \n",
    "        # display(times)\n",
    "        \n",
    "        merge_faster = times[[\"size\", \"merge\"]].rename(columns={\"merge\": \"faster\"}).copy()\n",
    "        merge_faster[\"faster\"] = times[\"merge\"] < times[\"selection\"]\n",
    "        # faster[\"selection\"] = ~faster[\"merge\"]\n",
    "        \n",
    "        if merge_faster.loc[0, \"faster\"]:\n",
    "            return merge_faster.loc[0, \"size\"]\n",
    "        \n",
    "        # display(merge_faster)\n",
    "        \n",
    "        col = merge_faster.faster.to_numpy()\n",
    "        if not (col[0] == col).all():\n",
    "            last_slower_index = merge_faster[~merge_faster[\"faster\"]].index[-1]\n",
    "            if last_slower_index+1 >= merge_faster.shape[0]:\n",
    "                continue\n",
    "            \n",
    "            last_slower_size = merge_faster.loc[last_slower_index, \"size\"]\n",
    "            first_faster_size = merge_faster.loc[last_slower_index+1, \"size\"]\n",
    "            \n",
    "            break\n",
    "    \n",
    "    # display(last_slower_index)\n",
    "    # display(last_slower_size)\n",
    "    \n",
    "    if first_faster_size - last_slower_size == 1:\n",
    "        return first_faster_size\n",
    "    \n",
    "    return find_crossover_point(base, last_slower_index, n, start_size=last_slower_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 20\n",
    "sizes = []\n",
    "for i in range(sample_size):\n",
    "    sizes.append(find_crossover_point(2, 10, 1000))\n",
    "    \n",
    "sum(sizes) / len(sizes)\n",
    "# run_exponential_sizes(32, 2, 5, 100, \"merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 61, 61, 59, 56, 55, 60, 55, 65, 59, 56, 65, 59, 61, 60, 61, 65, 65, 65, 65]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutdownJVM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
